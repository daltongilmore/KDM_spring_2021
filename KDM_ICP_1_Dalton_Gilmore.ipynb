{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KDM ICP 1 Dalton Gilmore",
      "provenance": [],
      "collapsed_sections": [
        "DVCvi7ksn52F",
        "3LVkRorG0Su5"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMI9HoPaM85fTDeKvmWLX6A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daltongilmore/KDM_spring_2021/blob/master/KDM_ICP_1_Dalton_Gilmore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzFUp73vmhLK"
      },
      "source": [
        "Firstly, import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGEAr9SxzwgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf855535-09f6-48f3-8b79-e6678b4d836c"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "import pandas as pd\r\n",
        "from nltk.tokenize import sent_tokenize\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.probability import FreqDist\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\r\n",
        "nltk.download('wordnet')\r\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k16QDOTSmpnC"
      },
      "source": [
        "Next step is to mount the google drive on the colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9DSmI-Lm8Jo",
        "outputId": "ffbd4569-e673-4298-ab2e-398efdb6592d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QE4V-XRnKtH"
      },
      "source": [
        "Then read the text file as a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "AcK1xLxjnSkY",
        "outputId": "4b2911c4-e4f6-4a08-ffad-12eebdd12918"
      },
      "source": [
        "dataset=pd.read_csv(\"/content/drive/MyDrive/data/input_file.txt\",delimiter=\"\\t\")\r\n",
        "dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text Analytics has lots of applications in today's online world. By analyzing tweets on Twitter, we can find trending news and peoples reaction on a particular event. Amazon can understand user feedback or review on the specific product. BookMyShow can discover people's opinion about the movie. Youtube can also analyze and understand peoples viewpoints on a video.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Text Analytics has lots of applications in today's online world. By analyzing tweets on Twitter, we can find trending news and peoples reaction on a particular event. Amazon can understand user feedback or review on the specific product. BookMyShow can discover people's opinion about the movie. Youtube can also analyze and understand peoples viewpoints on a video.]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loH09ZVNndDf"
      },
      "source": [
        "Convert the new dataframe into text for analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlqSRiYSnkWu",
        "outputId": "e3703a86-7c88-48e1-ebd6-774133e4e24d"
      },
      "source": [
        "text= dataset.to_string()\r\n",
        "print(text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Text Analytics has lots of applications in today's online world. By analyzing tweets on Twitter, we can find trending news and peoples reaction on a particular event. Amazon can understand user feedback or review on the specific product. BookMyShow can discover people's opinion about the movie. Youtube can also analyze and understand peoples viewpoints on a video.]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7VdMuunsIB"
      },
      "source": [
        "# Now perform 3 data analysis tasks on the imported text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVCvi7ksn52F"
      },
      "source": [
        "## *Task 1*: Remove **stopwords** from the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_B-5YytyrDf"
      },
      "source": [
        "- Break the text into individual words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKN9nrMFtMPb",
        "outputId": "6519e2f7-92ba-4200-ec0e-d06b4dcdbba8"
      },
      "source": [
        "tokenized_text=word_tokenize(text)\r\n",
        "print(tokenized_text)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Empty', 'DataFrame', 'Columns', ':', '[', 'Text', 'Analytics', 'has', 'lots', 'of', 'applications', 'in', 'today', \"'s\", 'online', 'world', '.', 'By', 'analyzing', 'tweets', 'on', 'Twitter', ',', 'we', 'can', 'find', 'trending', 'news', 'and', 'peoples', 'reaction', 'on', 'a', 'particular', 'event', '.', 'Amazon', 'can', 'understand', 'user', 'feedback', 'or', 'review', 'on', 'the', 'specific', 'product', '.', 'BookMyShow', 'can', 'discover', 'people', \"'s\", 'opinion', 'about', 'the', 'movie', '.', 'Youtube', 'can', 'also', 'analyze', 'and', 'understand', 'peoples', 'viewpoints', 'on', 'a', 'video', '.', ']', 'Index', ':', '[', ']']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR2NXT2gy1og"
      },
      "source": [
        "- Import python's list of stopwords for reference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdUzkTAWw09d",
        "outputId": "5974dcbb-d971-4436-d9cd-83cdde17b241"
      },
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "stop_words=set(stopwords.words(\"english\"))\r\n",
        "print(stop_words)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'yourself', \"you'd\", 'not', 'its', 'will', 'were', 'theirs', \"she's\", 'so', \"aren't\", 'needn', 'her', 'before', \"you've\", 'they', 'through', 'ain', 'myself', 'hers', 'don', \"should've\", 'an', \"hadn't\", 'the', 'hasn', 'ours', 'down', 'o', 'all', 'aren', 'haven', \"haven't\", 'very', 'itself', 'yours', 'what', 'over', 'who', 'couldn', 'has', 'until', 'should', \"doesn't\", 'did', 'she', 'but', 'with', \"isn't\", 'my', 'this', 'between', 'during', \"needn't\", 'again', \"it's\", 'you', 'under', 'do', 'them', 't', \"shan't\", 'up', \"you'll\", 'can', \"wouldn't\", 'whom', 'out', \"hasn't\", 'him', 'to', \"don't\", 'our', 'ourselves', 'which', 'm', 'nor', 'ma', 'same', 'hadn', 'most', 'didn', 'other', 's', 're', 'further', 'as', 'few', 'such', 'why', 'am', 'his', 'isn', 'mustn', 'a', 'into', \"you're\", 'doing', 'there', 'any', \"wasn't\", 'weren', 'from', 'does', 'about', 'd', 'doesn', 'above', 'your', 'or', 'own', \"mustn't\", 'herself', 'both', 'on', 'more', 'was', 'too', 'it', 've', \"didn't\", 'shan', 'by', 'being', \"shouldn't\", 'shouldn', 'yourselves', 'y', 'that', 'me', 'mightn', 'how', 'while', 'is', 'wasn', 'if', 'have', 'having', 'himself', 'where', 'some', 'wouldn', 'their', 'of', 'll', 'against', \"weren't\", 'in', 'be', 'been', 'just', 'only', 'we', 'because', 'those', 'at', 'below', \"mightn't\", 'and', 'he', 'no', 'themselves', 'i', 'had', 'these', 'are', 'now', 'off', \"couldn't\", 'then', \"that'll\", 'once', 'here', 'for', 'after', 'than', 'when', 'won', \"won't\", 'each'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBvVq9N7y7-t"
      },
      "source": [
        "- Filter through the tokenized text for stopwords and remove them to create the new list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61YCwYAsxZmP",
        "outputId": "ae3f5f4b-b0b8-48e3-d6de-263c434ddd91"
      },
      "source": [
        "no_stopwords_text=[]\r\n",
        "for i in tokenized_text:\r\n",
        "    if i not in stop_words:\r\n",
        "        no_stopwords_text.append(i)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized Sentence: ['Empty', 'DataFrame', 'Columns', ':', '[', 'Text', 'Analytics', 'has', 'lots', 'of', 'applications', 'in', 'today', \"'s\", 'online', 'world', '.', 'By', 'analyzing', 'tweets', 'on', 'Twitter', ',', 'we', 'can', 'find', 'trending', 'news', 'and', 'peoples', 'reaction', 'on', 'a', 'particular', 'event', '.', 'Amazon', 'can', 'understand', 'user', 'feedback', 'or', 'review', 'on', 'the', 'specific', 'product', '.', 'BookMyShow', 'can', 'discover', 'people', \"'s\", 'opinion', 'about', 'the', 'movie', '.', 'Youtube', 'can', 'also', 'analyze', 'and', 'understand', 'peoples', 'viewpoints', 'on', 'a', 'video', '.', ']', 'Index', ':', '[', ']']\n",
            "Text without stopwords: ['Empty', 'DataFrame', 'Columns', ':', '[', 'Text', 'Analytics', 'lots', 'applications', 'today', \"'s\", 'online', 'world', '.', 'By', 'analyzing', 'tweets', 'Twitter', ',', 'find', 'trending', 'news', 'peoples', 'reaction', 'particular', 'event', '.', 'Amazon', 'understand', 'user', 'feedback', 'review', 'specific', 'product', '.', 'BookMyShow', 'discover', 'people', \"'s\", 'opinion', 'movie', '.', 'Youtube', 'also', 'analyze', 'understand', 'peoples', 'viewpoints', 'video', '.', ']', 'Index', ':', '[', ']']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUBjRWJ9zWy7"
      },
      "source": [
        "- Print the original list of words and the list without stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT6tmzV9zcCL",
        "outputId": "9115ad33-de4d-443f-b736-c1ffa6a829a7"
      },
      "source": [
        "print(\"Original text:\", tokenized_text)\r\n",
        "print(\"Text without stopwords:\", no_stopwords_text)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text: ['Empty', 'DataFrame', 'Columns', ':', '[', 'Text', 'Analytics', 'has', 'lots', 'of', 'applications', 'in', 'today', \"'s\", 'online', 'world', '.', 'By', 'analyzing', 'tweets', 'on', 'Twitter', ',', 'we', 'can', 'find', 'trending', 'news', 'and', 'peoples', 'reaction', 'on', 'a', 'particular', 'event', '.', 'Amazon', 'can', 'understand', 'user', 'feedback', 'or', 'review', 'on', 'the', 'specific', 'product', '.', 'BookMyShow', 'can', 'discover', 'people', \"'s\", 'opinion', 'about', 'the', 'movie', '.', 'Youtube', 'can', 'also', 'analyze', 'and', 'understand', 'peoples', 'viewpoints', 'on', 'a', 'video', '.', ']', 'Index', ':', '[', ']']\n",
            "Text without stopwords: ['Empty', 'DataFrame', 'Columns', ':', '[', 'Text', 'Analytics', 'lots', 'applications', 'today', \"'s\", 'online', 'world', '.', 'By', 'analyzing', 'tweets', 'Twitter', ',', 'find', 'trending', 'news', 'peoples', 'reaction', 'particular', 'event', '.', 'Amazon', 'understand', 'user', 'feedback', 'review', 'specific', 'product', '.', 'BookMyShow', 'discover', 'people', \"'s\", 'opinion', 'movie', '.', 'Youtube', 'also', 'analyze', 'understand', 'peoples', 'viewpoints', 'video', '.', ']', 'Index', ':', '[', ']']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LVkRorG0Su5"
      },
      "source": [
        "## *Task 2*: Apply **part-of-speech tagging** to the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTs8T6CT1zSq"
      },
      "source": [
        "- Break the text into individual words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZELBz9n12R9",
        "outputId": "6dd1615b-a657-4c1a-b534-163c22515852"
      },
      "source": [
        "tokenized_text=word_tokenize(text)\r\n",
        "print(tokenized_text)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Empty', 'DataFrame', 'Columns', ':', '[', 'Text', 'Analytics', 'has', 'lots', 'of', 'applications', 'in', 'today', \"'s\", 'online', 'world', '.', 'By', 'analyzing', 'tweets', 'on', 'Twitter', ',', 'we', 'can', 'find', 'trending', 'news', 'and', 'peoples', 'reaction', 'on', 'a', 'particular', 'event', '.', 'Amazon', 'can', 'understand', 'user', 'feedback', 'or', 'review', 'on', 'the', 'specific', 'product', '.', 'BookMyShow', 'can', 'discover', 'people', \"'s\", 'opinion', 'about', 'the', 'movie', '.', 'Youtube', 'can', 'also', 'analyze', 'and', 'understand', 'peoples', 'viewpoints', 'on', 'a', 'video', '.', ']', 'Index', ':', '[', ']']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70xeRmGI2WhR"
      },
      "source": [
        "- Tag each word with its corresponding grammatical tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E11l7c4k17j6",
        "outputId": "ef2916fc-210b-41a6-dd32-5265a2f4ddd7"
      },
      "source": [
        "nltk.pos_tag(tokenized_text)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Empty', 'NNP'),\n",
              " ('DataFrame', 'NNP'),\n",
              " ('Columns', 'NNP'),\n",
              " (':', ':'),\n",
              " ('[', 'JJ'),\n",
              " ('Text', 'NNP'),\n",
              " ('Analytics', 'NNP'),\n",
              " ('has', 'VBZ'),\n",
              " ('lots', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('applications', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('today', 'NN'),\n",
              " (\"'s\", 'POS'),\n",
              " ('online', 'JJ'),\n",
              " ('world', 'NN'),\n",
              " ('.', '.'),\n",
              " ('By', 'IN'),\n",
              " ('analyzing', 'VBG'),\n",
              " ('tweets', 'NNS'),\n",
              " ('on', 'IN'),\n",
              " ('Twitter', 'NNP'),\n",
              " (',', ','),\n",
              " ('we', 'PRP'),\n",
              " ('can', 'MD'),\n",
              " ('find', 'VB'),\n",
              " ('trending', 'JJ'),\n",
              " ('news', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('peoples', 'NNS'),\n",
              " ('reaction', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('particular', 'JJ'),\n",
              " ('event', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Amazon', 'NNP'),\n",
              " ('can', 'MD'),\n",
              " ('understand', 'VB'),\n",
              " ('user', 'JJ'),\n",
              " ('feedback', 'NN'),\n",
              " ('or', 'CC'),\n",
              " ('review', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('specific', 'JJ'),\n",
              " ('product', 'NN'),\n",
              " ('.', '.'),\n",
              " ('BookMyShow', 'NNP'),\n",
              " ('can', 'MD'),\n",
              " ('discover', 'VB'),\n",
              " ('people', 'NNS'),\n",
              " (\"'s\", 'POS'),\n",
              " ('opinion', 'NN'),\n",
              " ('about', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('movie', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Youtube', 'NN'),\n",
              " ('can', 'MD'),\n",
              " ('also', 'RB'),\n",
              " ('analyze', 'VB'),\n",
              " ('and', 'CC'),\n",
              " ('understand', 'VB'),\n",
              " ('peoples', 'NNS'),\n",
              " ('viewpoints', 'NNS'),\n",
              " ('on', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('video', 'NN'),\n",
              " ('.', '.'),\n",
              " (']', 'JJ'),\n",
              " ('Index', 'NN'),\n",
              " (':', ':'),\n",
              " ('[', 'NN'),\n",
              " (']', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMRqoc8Z2sqZ"
      },
      "source": [
        "## *Task 3*: Normalize the text using **stemming**\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E2s0gR42sqg"
      },
      "source": [
        "- Break the text into individual words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZnL8flK2sqg",
        "outputId": "4b629ab3-e6a6-41c4-f43b-5fab919531b7"
      },
      "source": [
        "tokenized_text=word_tokenize(text)\r\n",
        "print(tokenized_text)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Empty', 'DataFrame', 'Columns', ':', '[', 'Text', 'Analytics', 'has', 'lots', 'of', 'applications', 'in', 'today', \"'s\", 'online', 'world', '.', 'By', 'analyzing', 'tweets', 'on', 'Twitter', ',', 'we', 'can', 'find', 'trending', 'news', 'and', 'peoples', 'reaction', 'on', 'a', 'particular', 'event', '.', 'Amazon', 'can', 'understand', 'user', 'feedback', 'or', 'review', 'on', 'the', 'specific', 'product', '.', 'BookMyShow', 'can', 'discover', 'people', \"'s\", 'opinion', 'about', 'the', 'movie', '.', 'Youtube', 'can', 'also', 'analyze', 'and', 'understand', 'peoples', 'viewpoints', 'on', 'a', 'video', '.', ']', 'Index', ':', '[', ']']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPQX9uNB_CTd"
      },
      "source": [
        "- Apply stemming to each word in the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JZ-OnVP7qzW"
      },
      "source": [
        "stemmer = PorterStemmer()\r\n",
        "text_stemmed=[]\r\n",
        "for i in tokenized_text:\r\n",
        "  text_stemmed.append(stemmer.stem(i))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJaL-DQk_K8k"
      },
      "source": [
        "- Print the original text alongside the new stemmed text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbyatUeq87-C",
        "outputId": "f2ee7398-f48b-426d-a8c7-4ef4c650eb42"
      },
      "source": [
        "print(\"Original words:\",tokenized_text)\r\n",
        "print(\"Stemmed words:\",text_stemmed)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original words: ['Empty', 'DataFrame', 'Columns', ':', '[', 'Text', 'Analytics', 'has', 'lots', 'of', 'applications', 'in', 'today', \"'s\", 'online', 'world', '.', 'By', 'analyzing', 'tweets', 'on', 'Twitter', ',', 'we', 'can', 'find', 'trending', 'news', 'and', 'peoples', 'reaction', 'on', 'a', 'particular', 'event', '.', 'Amazon', 'can', 'understand', 'user', 'feedback', 'or', 'review', 'on', 'the', 'specific', 'product', '.', 'BookMyShow', 'can', 'discover', 'people', \"'s\", 'opinion', 'about', 'the', 'movie', '.', 'Youtube', 'can', 'also', 'analyze', 'and', 'understand', 'peoples', 'viewpoints', 'on', 'a', 'video', '.', ']', 'Index', ':', '[', ']']\n",
            "Stemmed words: ['empti', 'datafram', 'column', ':', '[', 'text', 'analyt', 'ha', 'lot', 'of', 'applic', 'in', 'today', \"'s\", 'onlin', 'world', '.', 'By', 'analyz', 'tweet', 'on', 'twitter', ',', 'we', 'can', 'find', 'trend', 'news', 'and', 'peopl', 'reaction', 'on', 'a', 'particular', 'event', '.', 'amazon', 'can', 'understand', 'user', 'feedback', 'or', 'review', 'on', 'the', 'specif', 'product', '.', 'bookmyshow', 'can', 'discov', 'peopl', \"'s\", 'opinion', 'about', 'the', 'movi', '.', 'youtub', 'can', 'also', 'analyz', 'and', 'understand', 'peopl', 'viewpoint', 'on', 'a', 'video', '.', ']', 'index', ':', '[', ']']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}